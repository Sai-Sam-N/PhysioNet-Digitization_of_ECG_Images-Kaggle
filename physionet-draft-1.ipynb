{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97984,"databundleVersionId":14096757,"sourceType":"competition"},{"sourceId":677607,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":513841,"modelId":528480}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:06:39.057490Z","iopub.execute_input":"2026-01-10T14:06:39.057852Z","iopub.status.idle":"2026-01-10T14:06:45.397200Z","shell.execute_reply.started":"2026-01-10T14:06:39.057818Z","shell.execute_reply":"2026-01-10T14:06:45.396072Z"}},"outputs":[{"name":"stdout","text":"Collecting segmentation-models-pytorch\n  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.36.0)\nRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (2.0.2)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (11.3.0)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.6.2)\nRequirement already satisfied: timm>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (1.0.20)\nRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (2.8.0+cu126)\nRequirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.23.0+cu126)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.20.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.2.1rc0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.4.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8->segmentation-models-pytorch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.11.12)\nDownloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: segmentation-models-pytorch\nSuccessfully installed segmentation-models-pytorch-0.5.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nimport segmentation_models_pytorch as smp","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:06:47.440619Z","iopub.execute_input":"2026-01-10T14:06:47.441109Z","iopub.status.idle":"2026-01-10T14:06:58.621485Z","shell.execute_reply.started":"2026-01-10T14:06:47.441059Z","shell.execute_reply":"2026-01-10T14:06:58.620358Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Model added : physio-seg-public","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:06:58.623171Z","iopub.execute_input":"2026-01-10T14:06:58.624243Z","iopub.status.idle":"2026-01-10T14:06:58.628562Z","shell.execute_reply.started":"2026-01-10T14:06:58.624199Z","shell.execute_reply":"2026-01-10T14:06:58.627497Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Kaggle paths\nDATA_DIR = r\"/kaggle/input/physionet-ecg-image-digitization/\"\nMODEL_DIR = r\"/kaggle/input/physio-seg-public/pytorch/net3_009_4200/1\"\nTEST_IMG_DIR = os.path.join(DATA_DIR, r\"test\")\nTEST_CSV = os.path.join(DATA_DIR, r\"test.csv\")\nSAMPLE_SUB = os.path.join(DATA_DIR, r\"sample_submission.parquet\")\nOUT_SUB = r\"/kaggle/working/submission.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:10:19.408030Z","iopub.execute_input":"2026-01-10T14:10:19.408396Z","iopub.status.idle":"2026-01-10T14:10:19.414710Z","shell.execute_reply.started":"2026-01-10T14:10:19.408368Z","shell.execute_reply":"2026-01-10T14:10:19.413823Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:06:58.657860Z","iopub.execute_input":"2026-01-10T14:06:58.658314Z","iopub.status.idle":"2026-01-10T14:06:58.680639Z","shell.execute_reply.started":"2026-01-10T14:06:58.658271Z","shell.execute_reply":"2026-01-10T14:06:58.679254Z"}},"outputs":[{"name":"stdout","text":"Device: cpu\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model = smp.Unet(\n    encoder_name=\"resnet34\",\n    encoder_weights=None,\n    in_channels=3,\n    classes=1,\n    activation=None\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:06:58.682366Z","iopub.execute_input":"2026-01-10T14:06:58.683055Z","iopub.status.idle":"2026-01-10T14:06:59.137796Z","shell.execute_reply.started":"2026-01-10T14:06:58.682996Z","shell.execute_reply":"2026-01-10T14:06:59.136702Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Loading Kaggle Model Weights","metadata":{}},{"cell_type":"code","source":"ckpt_path = \"/kaggle/input/physio-seg-public/pytorch/net3_009_4200/1/iter_0004200.pt\"\nstate = torch.load(ckpt_path, map_location=device)\n\nif \"state_dict\" in state:\n    state = state[\"state_dict\"]\n\nnew_state = {}\nfor k, v in state.items():\n    if k.startswith(\"decoder.block.\"):\n        k = k.replace(\"decoder.block.\", \"decoder.blocks.\")\n    if k.startswith(\"pixel.\"):\n        k = k.replace(\"pixel.\", \"segmentation_head.0.\")\n    new_state[k] = v\n\nmodel.load_state_dict(new_state, strict=False)\nmodel.eval()\n\nprint(\"physio-seg-public loaded successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:06:59.139034Z","iopub.execute_input":"2026-01-10T14:06:59.140159Z","iopub.status.idle":"2026-01-10T14:07:00.429053Z","shell.execute_reply.started":"2026-01-10T14:06:59.140115Z","shell.execute_reply":"2026-01-10T14:07:00.428105Z"}},"outputs":[{"name":"stdout","text":"physio-seg-public loaded successfully\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/segmentation_models_pytorch/base/model.py:137: UserWarning: \n\n !!!!!! Mismatched keys !!!!!!\n\nYou should TRAIN the model to use it:\n - decoder.blocks.0.conv1.1.running_mean: torch.Size([128]) (weights) -> torch.Size([256]) (model)\n - decoder.blocks.0.conv1.1.weight: torch.Size([128]) (weights) -> torch.Size([256]) (model)\n - decoder.blocks.0.conv1.1.running_var: torch.Size([128]) (weights) -> torch.Size([256]) (model)\n - decoder.blocks.3.conv2.0.weight: torch.Size([16, 16, 3, 3]) (weights) -> torch.Size([32, 32, 3, 3]) (model)\n - decoder.blocks.1.conv1.1.running_var: torch.Size([64]) (weights) -> torch.Size([128]) (model)\n - decoder.blocks.1.conv2.1.bias: torch.Size([64]) (weights) -> torch.Size([128]) (model)\n - decoder.blocks.1.conv2.0.weight: torch.Size([64, 64, 3, 3]) (weights) -> torch.Size([128, 128, 3, 3]) (model)\n - decoder.blocks.1.conv1.1.bias: torch.Size([64]) (weights) -> torch.Size([128]) (model)\n - decoder.blocks.2.conv2.1.running_var: torch.Size([32]) (weights) -> torch.Size([64]) (model)\n - decoder.blocks.2.conv1.1.running_var: torch.Size([32]) (weights) -> torch.Size([64]) (model)\n - decoder.blocks.3.conv1.1.bias: torch.Size([16]) (weights) -> torch.Size([32]) (model)\n - segmentation_head.0.bias: torch.Size([4]) (weights) -> torch.Size([1]) (model)\n - decoder.blocks.3.conv2.1.bias: torch.Size([16]) (weights) -> torch.Size([32]) (model)\n - decoder.blocks.0.conv2.1.bias: torch.Size([128]) (weights) -> torch.Size([256]) (model)\n - decoder.blocks.3.conv1.0.weight: torch.Size([16, 34, 3, 3]) (weights) -> torch.Size([32, 128, 3, 3]) (model)\n - decoder.blocks.2.conv1.0.weight: torch.Size([32, 130, 3, 3]) (weights) -> torch.Size([64, 192, 3, 3]) (model)\n - decoder.blocks.2.conv1.1.bias: torch.Size([32]) (weights) -> torch.Size([64]) (model)\n - decoder.blocks.3.conv1.1.weight: torch.Size([16]) (weights) -> torch.Size([32]) (model)\n - decoder.blocks.0.conv2.0.weight: torch.Size([128, 128, 3, 3]) (weights) -> torch.Size([256, 256, 3, 3]) (model)\n - decoder.blocks.2.conv1.1.weight: torch.Size([32]) (weights) -> torch.Size([64]) (model)\n - decoder.blocks.2.conv2.1.running_mean: torch.Size([32]) (weights) -> torch.Size([64]) (model)\n - decoder.blocks.2.conv2.0.weight: torch.Size([32, 32, 3, 3]) (weights) -> torch.Size([64, 64, 3, 3]) (model)\n - decoder.blocks.0.conv2.1.running_var: torch.Size([128]) (weights) -> torch.Size([256]) (model)\n - decoder.blocks.1.conv1.1.running_mean: torch.Size([64]) (weights) -> torch.Size([128]) (model)\n - decoder.blocks.0.conv2.1.weight: torch.Size([128]) (weights) -> torch.Size([256]) (model)\n - decoder.blocks.0.conv1.0.weight: torch.Size([128, 770, 3, 3]) (weights) -> torch.Size([256, 768, 3, 3]) (model)\n - decoder.blocks.2.conv1.1.running_mean: torch.Size([32]) (weights) -> torch.Size([64]) (model)\n - decoder.blocks.1.conv1.1.weight: torch.Size([64]) (weights) -> torch.Size([128]) (model)\n - decoder.blocks.0.conv2.1.running_mean: torch.Size([128]) (weights) -> torch.Size([256]) (model)\n - decoder.blocks.1.conv2.1.running_var: torch.Size([64]) (weights) -> torch.Size([128]) (model)\n - decoder.blocks.3.conv2.1.running_var: torch.Size([16]) (weights) -> torch.Size([32]) (model)\n - decoder.blocks.2.conv2.1.weight: torch.Size([32]) (weights) -> torch.Size([64]) (model)\n - decoder.blocks.0.conv1.1.bias: torch.Size([128]) (weights) -> torch.Size([256]) (model)\n - decoder.blocks.3.conv1.1.running_var: torch.Size([16]) (weights) -> torch.Size([32]) (model)\n - decoder.blocks.1.conv1.0.weight: torch.Size([64, 258, 3, 3]) (weights) -> torch.Size([128, 384, 3, 3]) (model)\n - decoder.blocks.3.conv2.1.weight: torch.Size([16]) (weights) -> torch.Size([32]) (model)\n - decoder.blocks.1.conv2.1.weight: torch.Size([64]) (weights) -> torch.Size([128]) (model)\n - decoder.blocks.3.conv1.1.running_mean: torch.Size([16]) (weights) -> torch.Size([32]) (model)\n - segmentation_head.0.weight: torch.Size([4, 16, 1, 1]) (weights) -> torch.Size([1, 16, 3, 3]) (model)\n - decoder.blocks.3.conv2.1.running_mean: torch.Size([16]) (weights) -> torch.Size([32]) (model)\n - decoder.blocks.2.conv2.1.bias: torch.Size([32]) (weights) -> torch.Size([64]) (model)\n - decoder.blocks.1.conv2.1.running_mean: torch.Size([64]) (weights) -> torch.Size([128]) (model)\n\n  warnings.warn(text, stacklevel=-1)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Image Preprocessing","metadata":{}},{"cell_type":"code","source":"def load_image(path):\n    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img, (1024, 512))\n    img = img.astype(np.float32) / 255.0\n\n    # replicate grayscale → RGB\n    img = np.stack([img, img, img], axis=0)\n    return torch.from_numpy(img).unsqueeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:07:26.680761Z","iopub.execute_input":"2026-01-10T14:07:26.681485Z","iopub.status.idle":"2026-01-10T14:07:26.687934Z","shell.execute_reply.started":"2026-01-10T14:07:26.681443Z","shell.execute_reply":"2026-01-10T14:07:26.686834Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Inference Function","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef predict_mask(img_path):\n    x = load_image(img_path).to(device)\n    y = model(x)\n    y = torch.sigmoid(y)\n    return y.squeeze().cpu().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:07:42.506144Z","iopub.execute_input":"2026-01-10T14:07:42.506891Z","iopub.status.idle":"2026-01-10T14:07:42.512165Z","shell.execute_reply.started":"2026-01-10T14:07:42.506859Z","shell.execute_reply":"2026-01-10T14:07:42.511198Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"IMAGE_IDS = sorted(os.listdir(TEST_IMG_DIR))\n\nrecords = []\n\nfor name in tqdm(IMAGE_IDS):\n    img_path = os.path.join(TEST_IMG_DIR, name)\n\n    mask = predict_mask(img_path)\n\n    # simple Day-1 threshold\n    binary = (mask > 0.5).astype(np.uint8)\n\n    # flatten for submission (example format)\n    rle = binary.flatten().tolist()\n\n    records.append({\n        \"image_id\": name,\n        \"prediction\": \" \".join(map(str, rle))\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:10:30.787955Z","iopub.execute_input":"2026-01-10T14:10:30.788373Z","iopub.status.idle":"2026-01-10T14:11:15.860331Z","shell.execute_reply.started":"2026-01-10T14:10:30.788344Z","shell.execute_reply":"2026-01-10T14:11:15.859285Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2/2 [00:45<00:00, 22.53s/it]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"df = pd.DataFrame(records)\ndf.to_csv(OUT_SUB, index=False)\nprint(\"submission.csv saved\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:11:15.861948Z","iopub.execute_input":"2026-01-10T14:11:15.862352Z","iopub.status.idle":"2026-01-10T14:11:15.958819Z","shell.execute_reply.started":"2026-01-10T14:11:15.862323Z","shell.execute_reply":"2026-01-10T14:11:15.958006Z"}},"outputs":[{"name":"stdout","text":"submission.csv saved\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-10T14:11:22.403682Z","iopub.execute_input":"2026-01-10T14:11:22.404474Z","iopub.status.idle":"2026-01-10T14:11:22.455324Z","shell.execute_reply.started":"2026-01-10T14:11:22.404439Z","shell.execute_reply":"2026-01-10T14:11:22.454309Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"         image_id                                         prediction\n0  1053922973.png  0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...\n1  2352854581.png  0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1053922973.png</td>\n      <td>0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2352854581.png</td>\n      <td>0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}